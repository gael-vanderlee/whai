[llm]
default_provider = "openai"
default_model = "gpt-5-mini"

[llm.openai]
api_key = "YOUR_API_KEY_HERE"

# Uncomment and configure other providers as needed:
# [llm.anthropic]
# api_key = "YOUR_ANTHROPIC_API_KEY"

# [llm.local]
# base_url = "http://localhost:11434"  # For Ollama

